TrÃ¨s bonne remarque ğŸ‘Œ â€” et oui, tu peux tout Ã  fait mettre la dÃ©pendance du connecteur en scope compile dans ton projet Maven, Ã  condition que ton job Spark tourne dans un environnement oÃ¹ ton JAR applicatif contient dÃ©jÃ  tout (donc : pas de --packages externe Ã  runtime).

Mais il faut bien comprendre ce que cela implique ğŸ‘‡


---

ğŸ§© 1ï¸âƒ£ â€” Si tu veux embarquer le connecteur ClickHouse dans ton JAR

Tu peux dÃ©clarer dans ton pom.xml :

<dependency>
  <groupId>com.clickhouse.spark</groupId>
  <artifactId>clickhouse-spark-connector_2.12</artifactId>
  <version>0.7.2</version>
  <scope>compile</scope>
</dependency>

âœ… Cela fonctionne trÃ¨s bien si :

Tu packages ton projet en fat-jar / shaded JAR (via maven-shade-plugin ou assembly:single),

Et tu exÃ©cutes ton job Spark depuis une image Docker ou un cluster AKS oÃ¹ ton JAR complet est dÃ©jÃ  prÃ©sent.


âš ï¸ Si tu nâ€™inclus pas le connecteur dans ton JAR, Spark cherchera Ã  le tÃ©lÃ©charger dynamiquement (via --packages), ce qui ne marche pas derriÃ¨re proxy ou en environnement fermÃ© (Azure interne).


---

ğŸ§© 2ï¸âƒ£ â€” Exemple dâ€™usage du connecteur natif Spark ClickHouse

import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;

public class ClickHouseWriter {

    public static void write(Dataset<Row> df) {
        df.write()
            .format("clickhouse")
            .option("host", "https://<hostname>.privatelink.database.windows.net")
            .option("port", "8443")
            .option("user", "<USER>")
            .option("password", "<PASSWORD>")
            .option("database", "analytics")
            .option("table", "events")
            .option("ssl", "true")
            .option("create_table", "true")  // auto-create table if absent
            .mode("append")
            .save();
    }

    public static void main(String[] args) {
        SparkSession spark = SparkSession.builder()
                .appName("WriteToClickHouse")
                .getOrCreate();

        Dataset<Row> df = spark.read().json("/mnt/data/input.json");
        write(df);
    }
}


---

ğŸ§© 3ï¸âƒ£ â€” Exemple de maven-shade-plugin pour embarquer tout

<plugin>
  <groupId>org.apache.maven.plugins</groupId>
  <artifactId>maven-shade-plugin</artifactId>
  <version>3.3.0</version>
  <executions>
    <execution>
      <phase>package</phase>
      <goals><goal>shade</goal></goals>
      <configuration>
        <createDependencyReducedPom>false</createDependencyReducedPom>
        <transformers>
          <transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer">
            <mainClass>com.yourcompany.ClickHouseWriter</mainClass>
          </transformer>
        </transformers>
      </configuration>
    </execution>
  </executions>
</plugin>

Ce JAR contiendra Spark + ClickHouse Connector â†’ aucun --packages Ã  runtime.


---

ğŸ§  En rÃ©sumÃ©

Mode	DÃ©claration	Utilisation	RecommandÃ© quand

Compile (Shade)	<scope>compile</scope>	Tout embarquÃ© dans ton JAR	âœ… AKS / environnements fermÃ©s
Runtime (--packages)	rien dans POM	Ajout via spark-submit	Pour tests ou jobs temporaires
Provided	<scope>provided</scope>	Connecteur dÃ©jÃ  dans lâ€™image Docker	Si Spark runtime customisÃ©



---

Souhaites-tu que je te montre la version exacte du pom.xml complet (avec Spark, ClickHouse, Shade plugin et exclusions propres Ã  Spark 3.3.4) prÃªte Ã  compiler ton JAR AKS ?
