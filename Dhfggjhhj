Bien vu ‚Äî merci pour la correction üôè
Si Dev = DefaultToOAuthAuthentication: False et Prod = True, alors ce param√®tre n‚Äôexplique PAS ton √©chec d‚Äôeventlog.

Pourquoi ?

DefaultToOAuthAuthentication ne concerne que l‚Äôacc√®s via le portail Azure (et certains outils graphiques).
Le driver ABFS (abfss://) que Spark utilise s‚Äôauthentifie en OAuth via ta Managed Identity ind√©pendamment de ce flag.
Donc la panne en PROD vient ailleurs.

Ce qui reste (quasi s√ªr)

1. RBAC sur le conteneur (ou compte) pour la MI de PROD


2. ACL POSIX sur ADLS Gen2 (parents + spark-events) pour l‚ÄôOID de la MI


3. R√©seau (firewall/Private Endpoint)


4. Chemin/URL spark.eventLog.dir (typo, wasb/https au lieu de abfss)



Checks/Fix express (copier-coller)

1) RBAC ‚Äì la MI PROD a-t-elle le r√¥le data ?

# R√©cup√©rer les IDs de la MI
az identity show -g <RG_MI> -n <MI_NAME_PROD> \
  --query "{clientId:clientId, principalId:principalId, objectId:principalId}"

# Lister ses r√¥les
az role assignment list --assignee <principalId> --all --output table

# (Si manquant) Donner "Storage Blob Data Contributor" **au niveau du conteneur**
az role assignment create \
  --assignee <principalId> \
  --role "Storage Blob Data Contributor" \
  --scope /subscriptions/<SUB_ID>/resourceGroups/<RG_STORAGE>/providers/Microsoft.Storage/storageAccounts/<ACCOUNT>/blobServices/default/containers/<CONTAINER>

2) ACL POSIX ‚Äì donner acc√®s √† l‚ÄôOID de la MI

# Voir les ACL actuelles
az storage fs directory get-access-control \
  --account-name <ACCOUNT> --file-system <CONTAINER> --path "spark-events" --auth-mode login

# Traverser la racine (x) + acc√®s h√©rit√©s corrects
az storage fs directory set-access-control \
  --account-name <ACCOUNT> --file-system <CONTAINER> --path "" \
  --acl "user::r-x,group::r-x,other::---" --auth-mode login

az storage fs directory set-access-control \
  --account-name <ACCOUNT> --file-system <CONTAINER> --path "spark-events" \
  --acl "user::rwx,group::r-x,other::---" \
  --default-acl "user::rwx,group::r-x,other::---" --auth-mode login

# Ajouter explicitement la MI (UTILISE l'**objectId/principalId**, pas clientId)
az storage fs directory set-access-control \
  --account-name <ACCOUNT> --file-system <CONTAINER> --path "spark-events" \
  --acl "user:<OID_MI>:rwx" --default-acl "user:<OID_MI>:rwx" --auth-mode login

3) Test depuis un pod PROD (isole le probl√®me)

kubectl exec -it <POD_DRIVER> -- bash
hadoop fs -mkdir -p abfss://<CONTAINER>@<ACCOUNT>.dfs.core.windows.net/spark-events/_probe
hadoop fs -touchz   abfss://<CONTAINER>@<ACCOUNT>.dfs.core.windows.net/spark-events/_probe/test.ok
hadoop fs -ls       abfss://<CONTAINER>@<ACCOUNT>.dfs.core.windows.net/spark-events/_probe

mkdir OK mais touchz KO ‚áí write ACL manquante.

Tout KO ‚áí RBAC / r√©seau / identit√©.


4) Sanity c√¥t√© Spark

spark.eventLog.enabled=true
spark.eventLog.dir=abfss://<CONTAINER>@<ACCOUNT>.dfs.core.windows.net/spark-events
spark.hadoop.fs.azure.account.auth.type.<ACCOUNT>.dfs.core.windows.net=OAuth
spark.hadoop.fs.azure.account.oauth.provider.type.<ACCOUNT>.dfs.core.windows.net=org.apache.hadoop.fs.azurebfs.oauth2.MsiTokenProvider

(Assure-toi que c‚Äôest bien abfss:// et pas wasb/https/blobfuse.)


---

Si tu me donnes <ACCOUNT>, <CONTAINER>, <RG_STORAGE> et l‚ÄôOID de la MI PROD, je te renvoie les 3 commandes exactes √† lancer pour d√©bloquer l‚Äô√©criture.

