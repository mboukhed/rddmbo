Voici la config minimale et la config ‚Äúpropre‚Äù pour lancer un job Spark Python en mode Standalone (clair, terrain, pas de th√©orie inutile).


---

1Ô∏è‚É£ Pr√©-requis obligatoires

Sur tous les n≈ìuds (master + workers)

Java 8 / 11 / 17 (selon ta version Spark)

Python 3.x (m√™me version partout)

Spark install√© en standalone (pas YARN, pas K8s)


java -version
python3 --version
spark-submit --version


---

2Ô∏è‚É£ D√©marrer Spark Standalone

Sur le master

$SPARK_HOME/sbin/start-master.sh

Tu obtiens :

spark://MASTER_HOST:7077

UI :

http://MASTER_HOST:8080


---

Sur chaque worker

$SPARK_HOME/sbin/start-worker.sh spark://MASTER_HOST:7077

UI workers :

http://WORKER_HOST:8081


---

3Ô∏è‚É£ Configuration environnement (ESSENTIEL)

Python utilis√© par Spark

üëâ obligatoire sinon bug √† la con

export PYSPARK_PYTHON=/usr/bin/python3
export PYSPARK_DRIVER_PYTHON=/usr/bin/python3

(si virtualenv ‚Üí chemin du venv)


---

4Ô∏è‚É£ Job Spark Python minimal

Exemple job.py

from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("StandalonePythonJob") \
    .getOrCreate()

df = spark.range(0, 1000000)
print(df.count())

spark.stop()


---

5Ô∏è‚É£ spark-submit minimal (standalone)

spark-submit \
  --master spark://MASTER_HOST:7077 \
  --deploy-mode client \
  job.py

‚úÖ Client mode = le driver tourne l√† o√π tu lances la commande
‚ö†Ô∏è Cluster mode possible mais plus chiant en standalone


---

6Ô∏è‚É£ spark-submit recommand√© (r√©aliste prod)

spark-submit \
  --master spark://MASTER_HOST:7077 \
  --deploy-mode client \
  --name job-standalone-python \
  --executor-memory 4g \
  --executor-cores 2 \
  --total-executor-cores 8 \
  --conf spark.driver.memory=2g \
  --conf spark.sql.shuffle.partitions=200 \
  job.py


---

7Ô∏è‚É£ Cas classique : d√©pendances Python

Option A ‚Äî requirements.txt

spark-submit \
  --master spark://MASTER_HOST:7077 \
  --py-files deps.zip \
  job.py

(deps.zip = site-packages packag√©s)


---

Option B ‚Äî virtualenv (propre)

M√™me venv copi√© sur tous les n≈ìuds

export PYSPARK_PYTHON=/opt/venv/bin/python


---

8Ô∏è‚É£ Ports √† ouvrir (souvent oubli√©)

Usage	Port

Master	7077
Master UI	8080
Worker UI	8081
Driver	dynamique (firewall permissif recommand√©)



---

9Ô∏è‚É£ Probl√®mes fr√©quents (et solutions)

‚ùå Job reste bloqu√©

Workers non connect√©s au master

Mauvais spark://host:port

Firewall bloquant



---

‚ùå Python version mismatch

‚û°Ô∏è M√™me Python partout

which python3


---

‚ùå ImportError / ModuleNotFound

‚û°Ô∏è D√©pendances pas pr√©sentes sur les workers
‚û°Ô∏è Utiliser --py-files ou venv partag√©


---

10Ô∏è‚É£ TL;DR ultra court

‚úî Spark master + workers d√©marr√©s
‚úî PYSPARK_PYTHON d√©fini
‚úî spark-submit --master spark://...
‚úî M√™me Python & libs sur tous les n≈ìuds


---

Si tu veux, je peux te donner :

une config spark-env.sh compl√®te

un template prod (logging, retry, exit code)

une comparaison Standalone vs YARN vs K8s

ou adapter √ßa √† AKS / VM Azure / on-prem
