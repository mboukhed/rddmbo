Ok, lÃ  câ€™est clair ğŸ‘
Ton screenshot montre un vrai problÃ¨me ClickHouse cÃ´tÃ© serveur, pas un souci WebSSO ou Spark.
ğŸ’¥ Lâ€™erreur clÃ© (celle qui tue)
Copier le code

Code: 745. DB::Exception: CPU is overloaded
CPU is waiting for execution
(SERVER_OVERLOADED)
ğŸ‘‰ Ã‡a veut dire ClickHouse refuse volontairement la requÃªte
ğŸ‘‰ MÃ©canisme de protection interne, pas un crash
ğŸ§  Ce que ClickHouse te dit exactement
ClickHouse surveille :
le temps CPU rÃ©el
le temps CPU en attente (scheduler, cgroups, VM, conteneur)
Et il calcule un ratio :
Copier le code

os_cpu_wait_time_ratio
Dans ton cas :
Copier le code

ratio mesurÃ© â‰ˆ 2.50
seuil max â‰ˆ 2
â¡ï¸ Donc ClickHouse considÃ¨re que :
â€œJe passe trop de temps Ã  attendre du CPU â†’ je coupeâ€
âš ï¸ Causes rÃ©elles (dans 90 % des cas)
1ï¸âƒ£ ClickHouse sous-dimensionnÃ©
trop peu de CPU
VM / pod brideÌ par cgroups
node AKS surchargÃ©
ğŸ‘‰ Ultra courant sur AKS / Kubernetes
2ï¸âƒ£ Trop de requÃªtes concurrentes
Exemples :
Spark lance plein de partitions
Plusieurs jobs Spark en mÃªme temps
RequÃªtes lourdes (INSERT SELECT, OPTIMIZE, FINAL, JOIN)
3ï¸âƒ£ ClickHouse tourne en conteneur sans CPU garanti
Exemple AKS :
Yaml
Copier le code
resources:
  limits:
    cpu: "2"
  requests:
    cpu: "500m"
â¡ï¸ Le scheduler throttle â†’ ClickHouse panique â†’ 745
4ï¸âƒ£ Mauvaise affinitÃ© Spark â†” ClickHouse
trop de writers Spark
batch trop petit
inserts parallÃ¨les non maÃ®trisÃ©s
âœ… Solutions concrÃ¨tes (pas du blabla)
âœ”ï¸ Solution 1 â€” augmenter la tolÃ©rance ClickHouse (rapide)
Dans config.xml ou users.xml :
Xml
Copier le code
<profiles>
  <default>
    <max_os_cpu_wait_time_ratio>4</max_os_cpu_wait_time_ratio>
  </default>
</profiles>
âš ï¸ Ã‡a masque le problÃ¨me, mais dÃ©bloque vite.
âœ”ï¸ Solution 2 â€” limiter la concurrence (propre)
Xml
Copier le code
<max_concurrent_queries>50</max_concurrent_queries>
<max_threads>8</max_threads>
Et cÃ´tÃ© Spark :
Scala
Copier le code
spark.sql.shuffle.partitions=8
âœ”ï¸ Solution 3 â€” corriger AKS (trÃ¨s important)
Sur le pod ClickHouse :
Yaml
Copier le code
resources:
  requests:
    cpu: "4"
    memory: "16Gi"
  limits:
    cpu: "4"
    memory: "16Gi"
ğŸ‘‰ requests = limits (obligatoire pour ClickHouse)
âœ”ï¸ Solution 4 â€” Spark : arrÃªter le carnage
Si tu fais du write ClickHouse depuis Spark :
rÃ©duire :
numPartitions
writers parallÃ¨les
augmenter batch insert
Ã©viter foreachPartition mal contrÃ´lÃ©
ğŸ” Commandes de debug immÃ©diates
Dans ClickHouse :
Sql
Copier le code
SELECT *
FROM system.processes
ORDER BY elapsed DESC;
Sql
Copier le code
SELECT *
FROM system.metrics
WHERE metric LIKE '%CPU%';
Sql
Copier le code
SELECT *
FROM system.events
WHERE event LIKE '%Overload%';
ğŸ§© Conclusion nette
âŒ Ce nâ€™est PAS :
un bug JDBC
un problÃ¨me WebSSO
un problÃ¨me rÃ©seau
âœ… Câ€™est :
ClickHouse qui sâ€™auto-protÃ¨ge
CPU trop contraint (AKS + Spark)
Si tu veux, dis-moi :
AKS ou VM ?
CPU / RAM du pod ClickHouse
nb de writers Spark
INSERT SELECT ou INSERT VALUES ?
Je te donne la config exacte prod-safe pour Spark + ClickHouse ğŸ”¥
