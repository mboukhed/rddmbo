Excellente question üëå ‚Äî et c‚Äôest crucial quand tu √©cris dans ClickHouse depuis Spark ou JDBC, car les erreurs de type
Connection reset, No client available, ou SocketTimeoutException peuvent appara√Ætre sur de gros volumes ou longues transactions.


---

üéØ Objectif

Mettre en place un retry automatique et robuste en cas de perte de connexion ClickHouse (reset TCP, timeout, etc.), sans casser ton job Spark complet.


---

üß© 1Ô∏è‚É£ En Spark (niveau DataFrameWriter)

üß† Si tu utilises le ClickHouse Spark Connector (V2)

Tu peux activer le retry automatique via les options internes :

df.write()
  .format("clickhouse")
  .option("url", "clickhouse://localhost:8123/default")
  .option("user", "default")
  .option("password", "xxx")
  // param√®tres de retry
  .option("retry", "3")                   // nombre de tentatives
  .option("retry_interval", "3s")         // d√©lai entre tentatives
  .option("connect_timeout", "15s")
  .option("socket_timeout", "60s")
  .mode("append")
  .save();

üëâ Le connecteur g√®re un reconnect transparent √† chaque t√¢che Spark,
ce qui √©vite d‚Äô√©chouer le job entier pour un seul worker.


---

‚òï 2Ô∏è‚É£ En JDBC (pur Java)

Si tu passes par un ClickHouseConnection via JDBC, tu peux impl√©menter un retry manuel autour de ton ex√©cution SQL.

Exemple simple et propre :

public void executeWithRetry(String sql, int maxRetries) {
    int attempt = 0;
    while (true) {
        try (Connection conn = DriverManager.getConnection(
                "jdbc:clickhouse://localhost:9000/default", "default", "xxx");
             Statement stmt = conn.createStatement()) {

            stmt.execute(sql);
            return; // succ√®s
        } catch (SQLException e) {
            attempt++;
            if (attempt >= maxRetries) {
                throw new RuntimeException("Echec apr√®s " + maxRetries + " tentatives", e);
            }
            System.err.println("Connexion ClickHouse √©chou√©e, retry " + attempt + "/" + maxRetries);
            try {
                Thread.sleep(3000L * attempt); // backoff progressif
            } catch (InterruptedException ie) {
                Thread.currentThread().interrupt();
            }
        }
    }
}

‚úÖ Ce bloc :

G√®re les Connection reset by peer, SocketTimeoutException, No route to host‚Ä¶

Ferme proprement chaque connexion avant retry.

√âvite de saturer ClickHouse par des boucles trop rapides.



---

üîÅ 3Ô∏è‚É£ En Spark + JDBC (write en batch)

Si tu √©cris dans ClickHouse via JDBC (sans le connecteur natif) :

df.foreachPartition(rows -> {
    int retries = 3;
    while (retries > 0) {
        try (Connection conn = DriverManager.getConnection(jdbcUrl, user, password)) {
            conn.setAutoCommit(false);
            PreparedStatement ps = conn.prepareStatement(insertSql);
            for (Row r : rows) {
                // ps.set...()
                ps.addBatch();
            }
            ps.executeBatch();
            conn.commit();
            break; // succ√®s
        } catch (SQLException e) {
            retries--;
            System.err.println("Retry ClickHouse write, remaining: " + retries + " - " + e.getMessage());
            Thread.sleep(2000L);
        }
    }
});

‚úÖ Ce code g√®re :

La reconnexion automatique par partition Spark.

Un backoff progressif.

Une reprise propre m√™me apr√®s un ‚Äúconnection reset‚Äù.



---

üß† 4Ô∏è‚É£ En production (bonnes pratiques)

Bon r√©flexe	Description

Connexion courte par partition	Ouvre/ferme une connexion par batch, pas globale
Timeout raisonnable	connect_timeout=15s, socket_timeout=60s
Limiter le parall√©lisme	Trop de writers saturent ClickHouse (√©vite > 8 connexions)
Retry exponentiel	Attendre un peu plus √† chaque tentative
Logging clair	Log les query_id ou batchs √©chou√©s



---

üßæ En r√©sum√©

Situation	Solution

Spark Connector v2	.option("retry", "3").option("retry_interval", "3s")
JDBC simple	Boucle try/catch avec backoff (voir code)
Spark foreachPartition JDBC	Retry manuel par partition
Production stable	Timeout, peu de writers, retry exponentiel



---

Souhaites-tu que je te montre un exemple complet Java Spark (connector ClickHouse v2) avec gestion automatique du retry, des logs et du coalesce(2) pour ton cas pr√©cis ?
