Excellente question üëå ‚Äî pour activer le mode debug de l‚Äôint√©gration ClickHouse ‚Üî Spark, tu peux le faire √† plusieurs niveaux : Spark, ClickHouse-client, et ClickHouse-Spark-connector.
Voici les m√©thodes les plus efficaces selon ton contexte :


---

üß© 1. Activer le DEBUG dans Spark (niveau Java / log4j)

Ajoute dans ton log4j.properties (ou log4j2.xml) :

# Log g√©n√©ral Spark
log4j.rootCategory=INFO, console

# Active le debug ClickHouse Spark Connector
log4j.logger.org.apache.spark.sql.clickhouse=DEBUG
log4j.logger.com.clickhouse.spark=DEBUG
log4j.logger.com.clickhouse.client=DEBUG
log4j.logger.ru.yandex.clickhouse=DEBUG
log4j.logger.com.github.housepower=DEBUG

> üìÅ Fichier : src/main/resources/log4j.properties




---

‚öôÔ∏è 2. Activer le DEBUG par code (si tu ne veux pas modifier log4j)

Tu peux forcer le niveau de log via code au d√©marrage de ton SparkSession :

import org.apache.log4j.Logger;
import org.apache.log4j.Level;

Logger.getLogger("org.apache.spark.sql.clickhouse").setLevel(Level.DEBUG);
Logger.getLogger("com.clickhouse.spark").setLevel(Level.DEBUG);
Logger.getLogger("com.clickhouse.client").setLevel(Level.DEBUG);


---

üß† 3. C√¥t√© Spark submit ou test (param√®tres)

Ajoute dans ta commande spark-submit ou dans ton test Java :

--conf "spark.executor.extraJavaOptions=-Dlog4j.configuration=log4j.properties"
--conf "spark.driver.extraJavaOptions=-Dlog4j.configuration=log4j.properties"

ou, directement :

--conf "spark.driver.extraJavaOptions=-Dlog.level=DEBUG"


---

üßæ 4. V√©rifier les logs ClickHouse c√¥t√© serveur

Sur ton pod ClickHouse (ou instance), tu peux activer le niveau debug dans config.xml :

<yandex>
  <logger>
    <level>debug</level>
    <log>/var/log/clickhouse-server/clickhouse-server.log</log>
    <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>
  </logger>
</yandex>

Puis red√©marre le pod :

kubectl rollout restart statefulset clickhouse -n <namespace>


---

üß© 5. Option Spark Connector sp√©cifique (si tu utilises clickhouse-spark-connector)

Tu peux aussi ajouter :

spark.read()
     .format("clickhouse")
     .option("logLevel", "DEBUG")
     .option("verbose", "true")
     ...

ou dans ta config Spark :

--conf "spark.sql.clickhouse.log.level=DEBUG"


---

üí° Astuce pratique : inspection des logs Spark c√¥t√© ex√©cuteurs

Dans le Spark UI (souvent sur localhost:4040 si local), tu verras les logs d√©taill√©s com.clickhouse.spark.client et com.clickhouse.spark.result si tout est bien activ√©.


---

Souhaites-tu que je te montre un exemple complet de test Java Spark ClickHouse avec DEBUG activ√© (y compris configuration SparkSession et log4j) ?
√áa te permettrait de voir ligne par ligne ce que fait le connecteur.
