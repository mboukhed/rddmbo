Tu as raison : il ne faut pas relire tout le dossier Parquet, seulement les partitions que tu viens d‚Äô√©crire.
Voici 3 techniques fiables (avec code Java Spark) ‚Äî prends la #1, c‚Äôest la plus simple et robuste.


---

‚úÖ Technique #1 ‚Äî Relire par liste de chemins des partitions √©crites

Pendant/juste apr√®s l‚Äô√©criture, r√©cup√®re les valeurs de partition distinctes dans le DataFrame source (ou celui que tu as √©crit), construis les chemins Hive-style et relis uniquement ces chemins.

import org.apache.spark.sql.*;
import org.apache.spark.sql.Row;
import java.util.*;
import static org.apache.spark.sql.functions.*;

public class ReadJustWrittenPartitions {

  // Exemple: partitionCols = ["dt","hour"], basePath = ".../out/my_table/"
  public static Dataset<Row> readJustWritten(SparkSession spark,
                                             Dataset<Row> dfWrittenSource,
                                             String basePath,
                                             List<String> partitionCols) {
    // 1) Liste des partitions touch√©es (distinct)
    Dataset<Row> keys = dfWrittenSource.selectExpr(partitionCols.toArray(new String[0])).distinct();

    // 2) Collecte (le nb de partitions reste petit vs nb de lignes)
    List<Row> parts = keys.collectAsList();

    // 3) Construire les chemins Hive-style dt=2025-11-01/hour=13/
    List<String> paths = new ArrayList<>(parts.size());
    for (Row r : parts) {
      StringBuilder p = new StringBuilder(basePath);
      for (int i = 0; i < partitionCols.size(); i++) {
        String col = partitionCols.get(i);
        Object v = r.get(i);
        if (v == null) throw new IllegalStateException("Partition null pour " + col);
        p.append(col).append('=').append(v.toString()).append('/');
      }
      paths.add(p.toString());
    }

    // 4) Relire UNIQUEMENT ces partitions
    return spark.read().parquet(paths.toArray(new String[0]));
  }

  // Usage
  public static void main(String[] args) {
    SparkSession spark = SparkSession.builder().appName("read-new-partitions").getOrCreate();

    String base = "abfss://container@acct.dfs.core.windows.net/out/my_table/";
    List<String> partCols = Arrays.asList("dt","hour");

    // dfOut = ce que tu viens d‚Äô√©crire (ou sa version transform√©e avant write)
    Dataset<Row> dfOut = ...; // contient colonnes dt, hour

    // √âcriture (en n‚Äô√©crivant que certaines partitions)
    spark.conf().set("spark.sql.sources.partitionOverwriteMode", "dynamic"); // important si Overwrite
    dfOut.write().mode(SaveMode.Overwrite).partitionBy(partCols.toArray(new String[0])).parquet(base);

    // Relecture des seules partitions √©crites :
    Dataset<Row> justWritten = readJustWritten(spark, dfOut, base, partCols);

    // -> charge ensuite dans ClickHouse
    justWritten.writeTo("clickhouse.default.my_table").append();

    spark.stop();
  }
}

Pourquoi c‚Äôest bien :

Z√©ro scan de tout le dossier

Compatible HDFS/ABFS/S3

Pas de d√©pendance au metastore : on lit par chemins cibl√©s



---

üß∞ Technique #2 ‚Äî Relire par filtre sur partitions (si table enregistr√©e)

Si tu as enregistr√© la table Parquet dans le metastore (ou une table Iceberg/Delta), tu peux filtrer le partition prune c√¥t√© Spark :

// Table externe parquet d√©clar√©e: spark.sql("CREATE TABLE bronze.my_table USING parquet LOCATION '.../out/my_table/' PARTITIONED BY (dt, hour)")
Dataset<Row> justWritten = spark.table("bronze.my_table")
  .where(col("dt").isin("2025-11-01"))
  .where(col("hour").isin(13, 14)); // valeurs que tu viens d‚Äô√©crire

// puis vers ClickHouse v2
justWritten.writeTo("clickhouse.default.my_table").append();

> Ici Spark nira que les partitions correspondantes (partition pruning), mais il faut la table enregistr√©e.




---

üßæ Technique #3 ‚Äî Manifest des partitions √©crites

Si tu veux une tra√ßabilit√©, √©cris un manifest JSON des partitions touch√©es pendant le job, puis relis ce manifest pour construire la liste de chemins :

// 1) Construire un mini DF des partitions puis l‚Äô√©crire en JSON
Dataset<Row> manifest = dfOut.select("dt","hour").distinct();
manifest.coalesce(1).write().mode(SaveMode.Overwrite).json(base + "_manifest/run_2025-11-01T13-00Z/");

// 2) Plus tard, relire le manifest et composer les chemins
Dataset<Row> mf = spark.read().json(base + "_manifest/run_2025-11-01T13-00Z/");
List<Row> parts = mf.collectAsList();
// -> reconstruire les chemins comme en #1

> Utile pour des pipelines multi-√©tapes et des relances idempotentes.




---

R√©glages utiles

Overwrite s√©lectif :

spark.conf().set("spark.sql.sources.partitionOverwriteMode","dynamic")

‚ûú Spark n‚Äô√©crase que les partitions touch√©es (pas tout le dossier).

Sch√©mas : garde strictement les m√™mes noms/types entre Parquet et ClickHouse (ou mappe avant l‚Äôinsert).

Gros volumes : si you as des milliers de partitions par run, pr√©f√®re le manifest (#3) pour √©viter un collect() trop grand (m√™me si, en pratique, le nb de partitions touch√©es par run reste souvent raisonnable).



---

Mini-r√©sum√©

Le meilleur compromis : construire les chemins Hive-style des partitions que tu viens d‚Äô√©crire et relire uniquement ces chemins (#1).

Si tu as une table d√©clar√©e : filtre par colonnes de partition (#2) et laisse Spark faire le partition pruning.

Pour l‚Äôaudit et la relance : √©cris un manifest (#3).


Si tu me donnes tes colonnes de partition (ex. dt, hour, country‚Ä¶), je te fournis la m√©thode util exactement adapt√©e (String/Int/Date, formatage, null handling) + l‚Äôappel writeTo() ClickHouse v2 pr√™t √† coller.
