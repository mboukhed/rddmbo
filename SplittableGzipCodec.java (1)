
import java.io.EOFException;
import java.io.IOException;
import java.io.InputStream;

import org.apache.commons.codec.binary.Hex;
import org.apache.hadoop.io.compress.CompressionInputStream;
import org.apache.hadoop.io.compress.Decompressor;
import org.apache.hadoop.io.compress.GzipCodec;
import org.apache.hadoop.io.compress.SplitCompressionInputStream;
import org.apache.hadoop.io.compress.SplittableCompressionCodec;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;


public class SplittableGzipCodec extends GzipCodec implements
    SplittableCompressionCodec {

    private static final Logger LOG =
            LoggerFactory.getLogger(SplittableGzipCodec.class);

  private static final int DEFAULT_FILE_BUFFER_SIZE = 4 * 1024; // 4 KiB

  public SplittableGzipCodec() {
    super();
    LOG.info("Creating instance of SplittableGzipCodec");
  }

  public SplitCompressionInputStream createInputStream(
      final InputStream seekableIn, final Decompressor decompressor,
      final long start, final long end,
      final READ_MODE readMode) // Ignored by this codec
    throws IOException {
    LOG.info("Creating SplittableGzipInputStream (range = [{},{}])", start, end );
    return new SplittableGzipInputStream(createInputStream(seekableIn,
        decompressor), start, end, getConf().getInt("io.file.buffer.size",
          DEFAULT_FILE_BUFFER_SIZE));
  }

  // -------------------------------------------

  @Override
  public CompressionInputStream createInputStream(final InputStream in,
      final Decompressor decompressor) throws IOException {
    return new ThrottleableDecompressorStream(in,
        (decompressor == null) ? createDecompressor() : decompressor,
        getConf().getInt("io.file.buffer.size", DEFAULT_FILE_BUFFER_SIZE));
  }

  // ==========================================

  private static final class SplittableGzipInputStream extends
      SplitCompressionInputStream {

    // We start crawling when within 110% of the blocksize from the split.
    private static final float CRAWL_FACTOR = 1.1F;

    // Just to be sure we always crawl the last part a minimal crawling
    // distance is defined here... 128 bytes works fine.
    private static final int MINIMAL_CRAWL_DISTANCE = 128;

    // At what distance from the target do we HOLD the position reporting.
    // 128 bytes works fine (same as minimal crawl distance).
    private static final int POSITION_HOLD_DISTANCE = 128;

    // When setting log4j into TRACE mode we will report massive amounts
    // of info when this many bytes near the relevant areas.
    private static final int TRACE_REPORTING_DISTANCE = 64;

    private final ThrottleableDecompressorStream in;
    private final int crawlDistance;
    private final int bufferSize;

    // -------------------------------------------

    public SplittableGzipInputStream(final CompressionInputStream inputStream,
        final long start, final long end, final int inputStreamBufferSize)
      throws IOException {
      super(inputStream, start, end);

      bufferSize = inputStreamBufferSize;

      if (getAdjustedStart() > 0) { // If the entire file is really small (like 1000 bytes) we want to continue anyway.
        if (getAdjustedEnd() - getAdjustedStart() < bufferSize) {
          throw new IllegalArgumentException("The provided InputSplit " +
                  "(" + getAdjustedStart() + ";" + getAdjustedEnd() + "] " +
                  "is " + (getAdjustedEnd() - getAdjustedStart()) + " bytes which is too small. " +
                  "(Minimum is " + bufferSize + ")");
        }
      }

      // We MUST have the option of slowing down the reading of data.
      // This check will fail if someone creates a subclass that breaks this.
      if (inputStream instanceof ThrottleableDecompressorStream) {
        this.in = (ThrottleableDecompressorStream) inputStream;
      } else {
        this.in = null; // Permanently cripple this instance ('in' is final) .
        throw new IOException("The SplittableGzipCodec relies on"
            + " functionality in the ThrottleableDecompressorStream class.");
      }

      // When this close to the end of the split: crawl (read at most 1 byte
      // at a time) to avoid overshooting the end.
      // This calculates the distance at which we should switch to crawling.
      // Fact is that if the previous buffer is 1 byte further than this value
      // the end of the next block (+ 1 byte) will be the real point where we
      // will start the crawl. --> either 10% of the bufferSize or the Minimal
      // crawl distance value.
      this.crawlDistance = Math.max(Math.round(CRAWL_FACTOR * bufferSize),
          bufferSize + MINIMAL_CRAWL_DISTANCE);

      // Now we read the stream until we are at the start of this split.

      if (start == 0) {
        return; // That was quick; We're already where we want to be.
      }

      // Set the range we want to run over quickly.
      setStart(0);
      setEnd(start);

      // The target buffer to dump the discarded info to.
      final byte[] skippedBytes = new byte[bufferSize];

      LOG.debug("SKIPPING to position :{}", start);
      while (getPos() < start) {
        // This reads the input and decompresses the data.
        if (-1 == read(skippedBytes, 0, bufferSize)) {
          // An EOF while seeking for the START of the split !?!?
          throw new EOFException("Unexpected end of input stream when"
              + " seeking for the start of the split in"
              + " SplittableGzipCodec:"
              + " start=" + start + " adjustedStart=" + start + " position="
              + getPos());
        }
      }

      LOG.debug("ARRIVED at target location({}): {}", start, getPos());

      // Now we put the real split range values back.
      setStart(start);
      setEnd(end);

      // Set the reporting back to normal
      posState = POS_STATE.REPORT;
    }

    // -------------------------------------------

    /**
     * Position reporting states.
     */
    enum POS_STATE {
      REPORT, HOLD, SLOPE
    }

    private POS_STATE posState = POS_STATE.REPORT;

    /**
     * What do we call this state?
     *
     * @return String with state name useful for logging and debugging.
     */
    private String getStateName() {
      switch (posState) {
      case REPORT:
        return "REPORT";
      case HOLD:
        return "HOLD";
      case SLOPE:
        return "SLOPE";
      default:
        return "ERROR";
      }
    }

    // The reported position used in the HOLD and SLOPE states.
    private long reportedPos = 0;

    @Override
    public long getPos() {
      if (posState == POS_STATE.REPORT) {
        return getRealPos();
      }
      return reportedPos;
    }

    /**
     * The getPos position of the underlying input stream.
     *
     * @return number of bytes that have been read from the compressed input.
     */
    private long getRealPos() {
      return in.getBytesRead();
    }

    // -------------------------------------------

    @Override
    public int read(final byte[] b, final int off, final int len)
      throws IOException {
      final long currentRealPos = getRealPos();
      int maxBytesToRead = Math.min(bufferSize, len);

      final long adjustedEnd = getAdjustedEnd();
      final long adjustedStart = getAdjustedStart();
      if (adjustedStart >= adjustedEnd) {
        return -1; // Nothing to read in this split at all --> indicate EOF
      }

      final long distanceToEnd = adjustedEnd - currentRealPos;

      if (distanceToEnd <= crawlDistance) {
        // We go to a crawl as soon as we are close to the end (or over it).
        maxBytesToRead = 1;

        // We're getting close
        switch (posState) {
        case REPORT:
          // If we are within 128 bytes of the end we freeze the current value.
          if (distanceToEnd <= POSITION_HOLD_DISTANCE) {
            posState = POS_STATE.HOLD;
            reportedPos = currentRealPos;
            LOG.trace("STATE REPORT --> HOLD @ {}", currentRealPos);
          }
          break;

        case HOLD:
          // When we are ON/AFTER the real "end" then we start the slope.
          // If we start too early the last split may lose the last record(s).
          if (distanceToEnd <= 0) {
            posState = POS_STATE.SLOPE;
            LOG.trace("STATE HOLD --> SLOPE @ {}", currentRealPos);
          }
          break;

        case SLOPE:
          // We are reading 1 byte at a time and reporting 1 byte at a time.
          ++reportedPos;
          break;

        default:
          break;
        }

      } else {
        // At a distance we always do normal reporting
        // Set the state explicitly: the "end" value can change.
        posState = POS_STATE.REPORT;
      }

      // Debugging facility
      if (LOG.isTraceEnabled()) {
        // When tracing do the first few bytes at crawl speed too.
        final long distanceFromStart = currentRealPos - adjustedStart;
        if (distanceFromStart <= TRACE_REPORTING_DISTANCE) {
          maxBytesToRead = 1;
        }
      }

      // Set the input read step to tune the disk reads to the wanted speed.
      in.setReadStep(maxBytesToRead);

      // Actually read the information.
      final int bytesRead = in.read(b, off, maxBytesToRead);

      // Debugging facility
      if (LOG.isTraceEnabled()) {
        if (bytesRead == -1) {
          LOG.trace("End-of-File");
        } else {
          // Report massive info on the LAST 64 bytes of the split
          if (getPos() >= getAdjustedEnd() - TRACE_REPORTING_DISTANCE
              && bytesRead < 10) {
            final String bytes = new String(b).substring(0, bytesRead);
            LOG.trace("READ TAIL {} bytes ({} pos = {}/{}): ##{}## HEX:##{}##",
                      bytesRead, getStateName(), getPos(), getRealPos(),
                      bytes, new String(Hex.encodeHex(bytes.getBytes())));
          }

          // Report massive info on the FIRST 64 bytes of the split
          if (getPos() <= getAdjustedStart() + TRACE_REPORTING_DISTANCE
              && bytesRead < 10) {
            final String bytes = new String(b).substring(0, bytesRead);
            LOG.trace("READ HEAD {} bytes ({} pos = {}/{}): ##{}## HEX:##{}##",
                      bytesRead, getStateName(), getPos(), getRealPos(),
                      bytes, new String(Hex.encodeHex(bytes.getBytes())));
          }
        }
      }

      return bytesRead;
    }

    // -------------------------------------------

    @Override
    public void resetState() throws IOException {
      in.resetState();
    }

    // -------------------------------------------

    @Override
    public int read() throws IOException {
      return in.read();
    }

    // -------------------------------------------
  }


}