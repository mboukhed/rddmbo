Excellent r√©flexe üëå ‚Äî la correspondance du type Decimal Spark ‚Üí ClickHouse est un point crucial,
car ClickHouse a besoin de conna√Ætre pr√©cision et scale d√®s la cr√©ation de la table.


---

üéØ Objectif

> Quand ton DataFrame contient des colonnes DecimalType(precision, scale),
la table ClickHouse doit utiliser le type exact Decimal(precision, scale).




---

üß© 1Ô∏è‚É£  Mapping complet Spark ‚Üí ClickHouse

Voici la table des correspondances correctes :

Type Spark (DataType)	Type ClickHouse	Remarques

StringType	String	‚Äî
BooleanType	UInt8	Pas de type bool√©en natif CH
ByteType	Int8	‚Äî
ShortType	Int16	‚Äî
IntegerType	Int32	‚Äî
LongType	Int64	‚Äî
FloatType	Float32	‚Äî
DoubleType	Float64	‚Äî
DateType	Date	‚Äî
TimestampType	DateTime	‚Äî
DecimalType(p,s)	Decimal(p,s)	doit inclure pr√©cision et scale



---

üß© 2Ô∏è‚É£  Exemple concret de conversion Java

Voici une m√©thode Java compl√®te qui convertit un sch√©ma Spark en DDL ClickHouse,
avec gestion correcte du DecimalType :

import org.apache.spark.sql.types.*;

public class SparkToClickHouseTypeMapper {

    public static String sparkToClickHouseType(DataType dt) {
        if (dt instanceof StringType) return "String";
        if (dt instanceof BooleanType) return "UInt8";
        if (dt instanceof ByteType) return "Int8";
        if (dt instanceof ShortType) return "Int16";
        if (dt instanceof IntegerType) return "Int32";
        if (dt instanceof LongType) return "Int64";
        if (dt instanceof FloatType) return "Float32";
        if (dt instanceof DoubleType) return "Float64";
        if (dt instanceof DateType) return "Date";
        if (dt instanceof TimestampType) return "DateTime";
        if (dt instanceof DecimalType dec) {
            return "Decimal(" + dec.precision() + "," + dec.scale() + ")";
        }
        // fallback pour Array, Struct, etc.
        return "String";
    }
}


---

üß© 3Ô∏è‚É£  G√©n√©ration automatique de la table avec Decimal inclus

Exemple :

StructType schema = df.schema();

String cols = Arrays.stream(schema.fields())
    .map(f -> f.name() + " " + SparkToClickHouseTypeMapper.sparkToClickHouseType(f.dataType()))
    .collect(Collectors.joining(", "));

String ddl = "CREATE TABLE IF NOT EXISTS clickhouse.srv.avia_partition (" +
             cols + ", last_update DateTime DEFAULT now()" +
             ") ENGINE = ReplacingMergeTree(last_update) ORDER BY tuple()";

spark.sql(ddl);

üëâ Si ton DataFrame contient une colonne Spark DecimalType(18,4),
tu obtiendras :

CREATE TABLE srv.avia_partition (
  amount Decimal(18,4),
  ...
) ENGINE = ReplacingMergeTree(last_update)
ORDER BY tuple()


---

üß© 4Ô∏è‚É£  Variante avec createTableOptions

Tu peux aussi laisser Spark cr√©er la table automatiquement,
et juste ajouter le moteur :

df.write()
  .format("clickhouse")
  .option("database", "srv")
  .option("table", "avia_partition")
  .option("createTableOptions", "ENGINE=ReplacingMergeTree(last_update) ORDER BY tuple()")
  .mode("append")
  .save();

‚ö†Ô∏è Dans ce cas, le connecteur ClickHouse utilise le mapping par d√©faut (DecimalType ‚Üí Decimal(p,s)),
donc ton DF doit avoir une DecimalType correctement d√©finie dans son sch√©ma (pas DecimalType.Unlimited).


---

‚úÖ 5Ô∏è‚É£  R√©capitulatif

Cas	Solution

Spark conna√Æt pr√©cision/scale	DecimalType(p,s) ‚Üí Decimal(p,s) auto
Tu g√©n√®res la DDL toi-m√™me	Utilise la fonction sparkToClickHouseType() ci-dessus
Tu laisses Spark cr√©er	.option("createTableOptions", "ENGINE=... ORDER BY tuple()")
Table existante	Doit d√©j√† d√©finir Decimal(p,s) correct, sinon conversion √©chouera



---

Souhaites-tu que je te g√©n√®re un petit utilitaire Java complet qui cr√©e automatiquement la table ClickHouse √† partir d‚Äôun Dataset<Row> (en d√©tectant aussi les DecimalType) ?
