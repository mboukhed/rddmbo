Ã‡a arrive souvent quand on pousse de gros batches vers ClickHouse : la connexion HTTP se coupe en plein insert (â€œConnection reset / Server failed to respondâ€).
Voici un plan pragmatique (cÃ´tÃ© Spark + ClickHouse + rÃ©seau) qui rÃ¨gle 90% des cas.

1) CÃ´tÃ© Spark / Connecteur V2

Dans ton SparkApplication.yaml (Spark Operator) ou dans ton code, ajoute/ajuste ces confs :

spec:
  sparkConf:
    # â€” rÃ©duire la taille des lots et compresser â€”
    "spark.clickhouse.write.batchSize": "5000"          # 5kâ€“20k selon essais
    "spark.clickhouse.write.compression.codec": "lz4"   # par dÃ©faut lz4, garde

    # â€” format dâ€™insert : JSON souvent plus robuste que Arrow â€”
    "spark.clickhouse.write.format": "json"             # par dÃ©faut 'arrow'

    # â€” aligner la distribution : Ã©viter des mega-batches irrÃ©guliers â€”
    "spark.clickhouse.write.repartitionByPartition": "true"
    "spark.clickhouse.write.repartitionStrictly": "false"
    "spark.clickhouse.write.localSortByKey": "true"

    # â€” tolÃ©rance aux erreurs transitoires + retries â€”
    "spark.clickhouse.write.maxRetry": "5"
    "spark.clickhouse.write.retryInterval": "15s"
    # Ajouter des codes rÃ©ellement transitoires (timeouts, network, etc.)
    "spark.clickhouse.write.retryableErrorCodes": "159,202,203,209,210,242,252,285,319"

batchSize plus petit â†’ requÃªtes plus courtes, moins de â€œresetâ€.

write.format=json â†’ moins sensible aux soucis de client/Arrow.

retryableErrorCodes inclut 209 (SOCKET_TIMEOUT) et 210 (NETWORK_ERROR) etc., considÃ©rÃ©s transitoires par lâ€™Ã©cosystÃ¨me ClickHouse. 


ğŸ‘‰ Et adapte le parallÃ©lisme de lâ€™insert pour ne pas saturer CH :
df = df.repartition(<nb raisonnable>, col("partition_key"))
(Ã©vite 1000 requÃªtes concurrentes Ã©normes).

2) Si HTTP est instable, passe en TCP natif

Le connecteur V2 supporte TCP via le catalog :

spec:
  sparkConf:
    "spark.sql.catalog.clickhouse": "com.clickhouse.spark.ClickHouseCatalog"
    "spark.sql.catalog.clickhouse.protocol": "tcp"
    "spark.sql.catalog.clickhouse.tcp_port": "9000"
    "spark.sql.catalog.clickhouse.host": "clickhouse.default.svc.cluster.local"
    "spark.sql.catalog.clickhouse.user": "default"
    "spark.sql.catalog.clickhouse.password": "<secret>"

Le TCP est souvent plus tolÃ©rant aux proxies/Ingress que HTTP/8123. Le support tcp_port est documentÃ© dans les releases du connecteur. 

3) Timeouts/Keep-alive (client)

Les timeouts viennent du driver Java/JDBC utilisÃ© par le connecteur.
Selon ton setup, augmente socket_timeout cÃ´tÃ© client (ms) ; câ€™est un paramÃ¨tre standard des stacks CH. (Ex. de refs publiques montrant lâ€™usage de socket_timeout.) 

4) CÃ´tÃ© ClickHouse (serveur)

VÃ©rifie les logs (clickhouse-server.log) pour confirmer des SOCKET_TIMEOUT (209) / NETWORK_ERROR (210) cÃ´tÃ© serveur. 

Si tu Ã©cris sur une table Distributed, tu peux rÃ©duire les sauts rÃ©seau :

Ã‰crire sur les tables locales en activant (si pertinent) :

"spark.clickhouse.write.distributed.convertLocal": "true"
"spark.clickhouse.write.distributed.useClusterNodes": "true"

(diminue les risques de reset via le nÅ“ud distributeur). 



5) CÃ´tÃ© AKS / rÃ©seau (trÃ¨s frÃ©quent)

Les â€œconnection resetâ€ viennent souvent dâ€™un Ingress/Load Balancer qui coupe la socket sur les gros uploads (INSERT). Solutions :

Si ClickHouse est derriÃ¨re NGINX Ingress, augmente proxy_read_timeout, proxy_send_timeout et client_max_body_size, ou bypasse lâ€™Ingress pour les flux Spark â†’ CH (Service ClusterIP headless).

VÃ©rifie aussi les idles sur ton LB (Azure) qui peuvent tuer la connexion longue.


6) Checklist express

ğŸ”§ RÃ©duis spark.clickhouse.write.batchSize (5kâ€“20k) + write.format=json. 

ğŸ” Active maxRetry, retryInterval, et ajoute 209,210,â€¦ aux retryableErrorCodes. 

ğŸ§© repartitionByPartition=true + localSortByKey=true + coalesce/repartition cÃ´tÃ© DF. 

ğŸ”Œ En cas de resets persistants : passe HTTP â†’ TCP (9000) via le catalog. 

ğŸŒ Ã‰vite lâ€™Ingress pour les inserts massifs, ou augmente ses timeouts.

ğŸ“œ Regarde les logs CH pour 209/210 afin de confirmer la nature â€œrÃ©seau/timeoutâ€. 


Si tu veux, je te prÃ©pare un YAML SparkApplication complet (HTTP et variante TCP) + un snippet Java qui lit les secrets dâ€™env et applique ces confs automatiquement.
