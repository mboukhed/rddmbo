


---

üîç 1. Pourquoi cette erreur appara√Æt

Elle arrive typiquement dans ces cas :

Le proxy Ingress (souvent NGINX ou Azure App Gateway) ferme la connexion avant la fin (timeout trop court).

ClickHouse prend trop de temps pour envoyer les donn√©es.

Le flux HTTP est chunk√© (envoy√© par morceaux), mais la derni√®re partie n‚Äôest jamais re√ßue.

Spark ou HttpClient attend encore des donn√©es ‚Üí ConnectionClosedException.



---

‚úÖ 2. √âtapes pour corriger

√âtape 1 ‚Äî V√©rifie si le probl√®me vient du proxy

Fais un port-forward direct vers ClickHouse, sans passer par l‚Äôingress :

kubectl -n <ton-namespace> port-forward svc/<nom-du-service-clickhouse> 8123:8123

Puis, dans ton code Java :

.option("url", "http://127.0.0.1:8123")

‚û°Ô∏è Si √ßa fonctionne sans erreur ‚Üí c‚Äôest bien l‚Äôingress ou le proxy AKS qui coupe la connexion.


---

√âtape 2 ‚Äî Allonge les timeouts du proxy (Ingress NGINX)

Ajoute ou modifie les annotations suivantes dans le YAML de ton ingress :

metadata:
  annotations:
    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-body-size: "0"
    nginx.ingress.kubernetes.io/proxy-buffering: "on"
    nginx.ingress.kubernetes.io/proxy-request-buffering: "off"
    nginx.ingress.kubernetes.io/keepalive: "64"

‚û°Ô∏è Si tu utilises Azure Application Gateway Ingress Controller (AGIC), augmente aussi le param√®tre :

backend-request-timeout = 600


---

√âtape 3 ‚Äî Ajuste les timeouts c√¥t√© ClickHouse

Sur le serveur ClickHouse, ex√©cute :

SET send_timeout = 300;
SET receive_timeout = 300;
SET keep_alive_timeout = 300;
SET max_execution_time = 0;

ou modifie ces param√®tres dans config.xml.


---

√âtape 4 ‚Äî Ajuste les options Spark/ClickHouse c√¥t√© client

Continue √† d√©finir tes options Spark, mais ajoute ces lignes :

spark.conf().set("spark.sql.catalog.clickhouse.option.compress", "0"); // d√©sactive la compression
spark.conf().set("spark.sql.catalog.clickhouse.option.custom_http_params",
                 "wait_end_of_query=1&send_progress_in_http_headers=1");
spark.conf().set("spark.sql.catalog.clickhouse.option.socket_timeout",  "300000");
spark.conf().set("spark.sql.catalog.clickhouse.option.connect_timeout", "120000");
spark.conf().set("spark.sql.catalog.clickhouse.option.http_receive_timeout", "300000");
spark.conf().set("spark.sql.catalog.clickhouse.option.http_send_timeout", "300000");

‚û°Ô∏è Pourquoi ?

La compression (compress=1) cr√©e parfois des chunks corrompus via proxy.

Le param√®tre wait_end_of_query s‚Äôassure que Spark attend la fin compl√®te de la r√©ponse.

Les timeouts plus longs √©vitent les coupures pendant les requ√™tes volumineuses.



---

√âtape 5 ‚Äî R√©duis le volume pour les tests

Pendant tes essais :

SELECT * FROM ma_table LIMIT 10;

ou dans Spark :

df.limit(10).show(false);

Cela permet de v√©rifier le flux sans transfert massif de donn√©es.


---

üß© En r√©sum√©

C√¥t√©	Action

Ingress AKS (NGINX/App GW)	Augmente proxy-read-timeout, proxy-send-timeout, backend-request-timeout
ClickHouse serveur	Augmente send_timeout, receive_timeout, keep_alive_timeout
Client Spark	D√©sactive compress, ajoute wait_end_of_query, augmente les timeouts
Test	Essaie un LIMIT 10 pour valider le flux HTTP



---

üëâ Si tu veux, je peux te montrer exactement les lignes √† ajouter dans ton YAML d‚Äôingress AKS et ton script Spark Java complet (avec tous les spark.conf().set(...)) pour corriger d√©finitivement cette erreur.
Souhaites-tu que je te le pr√©pare ?
